{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.amp import GradScaler, autocast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from ResNext_CBAM.CBAM_conv import CBAM\n",
    "from ResNext_CBAM.ResNext_bottleneck import Resnext_bottleneck_block, Resnext_bottleneck_transpose_block\n",
    "\n",
    "def rao_split(rao_amp_df, rao_amp_iso_df):\n",
    "    rao_res = rao_amp_df[:, :, :10] - rao_amp_iso_df\n",
    "    rao_iso = rao_amp_iso_df\n",
    "    return rao_res, rao_iso\n",
    "\n",
    "rao_res, rao_iso = rao_split(rao_amp_df, rao_amp_iso_df)\n",
    "\n",
    "X_train, X_test, iso_train, iso_test, res_train, res_test = train_test_split(\n",
    "    features_df,\n",
    "    rao_iso,\n",
    "    rao_res,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_in = MinMaxScaler()\n",
    "scaler_in.fit(X_train)\n",
    "X_train_scaled = scaler_in.transform(X_train)\n",
    "X_test_scaled = scaler_in.transform(X_test)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32, device=device)\n",
    "X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32, device=device)\n",
    "iso_train_t = torch.tensor(iso_train, dtype=torch.float32, device=device)\n",
    "iso_test_t = torch.tensor(iso_test, dtype=torch.float32, device=device)\n",
    "res_train_t = torch.tensor(res_train, dtype=torch.float32, device=device)\n",
    "res_test_t = torch.tensor(res_test, dtype=torch.float32, device=device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, iso_train_t, res_train_t)\n",
    "test_dataset = TensorDataset(X_test_t, iso_test_t, res_test_t)\n",
    "\n",
    "def set_seed(seed_value):\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class Stage1Model(nn.Module):\n",
    "    def __init__(self, decoder_in, out_size, conv_block, convt_block, n_blocks,\n",
    "                 decoder_channel_shrink=1, width_ratio=1, use_cbam=(True, False, True, False),\n",
    "                 CBAM=None, CBAM_skip=False):\n",
    "        super(Stage1Model, self).__init__()\n",
    "        self.in_channels, self.in_height, self.in_width = decoder_in\n",
    "        self.out_height, self.out_width = out_size\n",
    "        self.width_ratio = width_ratio\n",
    "        self.CBAM = CBAM\n",
    "\n",
    "        self.in_channels_forward = self.in_channels\n",
    "        self.channel_shrink_rate = decoder_channel_shrink\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(7, self.in_channels),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.decoder_fc = nn.Sequential(\n",
    "            nn.Linear(self.in_channels, self.in_channels * self.in_height * self.in_width),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Decoder layers\n",
    "        self.layer1 = self._make_layer('layer1', conv_block, convt_block,\n",
    "                                       self.in_channels_forward // self.channel_shrink_rate,\n",
    "                                       n_blocks[0], stride=2, shrink=self.width_ratio,\n",
    "                                       cardinality=32, convt_padd=(2, 1),\n",
    "                                       use_cbam=use_cbam[0], CBAM_skip=CBAM_skip)\n",
    "        self.layer2 = self._make_layer('layer2', conv_block, convt_block,\n",
    "                                       self.in_channels_forward // (self.channel_shrink_rate * 2),\n",
    "                                       n_blocks[1], stride=2, shrink=self.width_ratio,\n",
    "                                       cardinality=32, use_cbam=use_cbam[1],\n",
    "                                       CBAM_skip=CBAM_skip)\n",
    "        self.layer3 = self._make_layer('layer3', conv_block, convt_block,\n",
    "                                       self.in_channels_forward // (self.channel_shrink_rate * 4),\n",
    "                                       n_blocks[2], stride=2, shrink=self.width_ratio,\n",
    "                                       cardinality=32, convt_padd=(1, 3),\n",
    "                                       convt_out_padd=(1, 0),\n",
    "                                       use_cbam=use_cbam[2], CBAM_skip=CBAM_skip)\n",
    "        self.layer4 = self._make_layer('layer4', conv_block, convt_block,\n",
    "                                       1,\n",
    "                                       n_blocks[3], stride=2, shrink=self.width_ratio,\n",
    "                                       cardinality=1, convt_out_padd=(1, 1),\n",
    "                                       use_cbam=use_cbam[3], CBAM_skip=CBAM_skip)\n",
    "\n",
    "        self.iso_conv = nn.Conv2d(1, 1, kernel_size=1, stride=1, padding=0)\n",
    "        self.final_fc=nn.Linear(360,360)\n",
    "\n",
    "        # Initialization\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, name, conv_block, convt_block, out_channels, n_block, stride, shrink,\n",
    "                    convt_padd=(1, 1), convt_out_padd=(0, 0), cardinality=32,\n",
    "                    reduc_ratio_CBAM=16, use_cbam=True, CBAM_skip=False):\n",
    "        layers = nn.Sequential()\n",
    "        for block_idx in range(n_block):\n",
    "            name_ = f'{name}_block_{block_idx}'\n",
    "            if block_idx == 0:\n",
    "                layers.add_module(name_, convt_block(\n",
    "                    self.in_channels, out_channels, stride=stride,\n",
    "                    cardinality=cardinality, shrink=shrink,\n",
    "                    convt_padd=convt_padd, convt_out_padd=convt_out_padd,\n",
    "                    reduc_ratio_CBAM=reduc_ratio_CBAM,\n",
    "                    use_cbam=use_cbam,\n",
    "                    CBAM=self.CBAM,\n",
    "                    CBAM_skip=CBAM_skip))\n",
    "                self.in_channels = out_channels\n",
    "            else:\n",
    "                layers.add_module(name_, conv_block(\n",
    "                    self.in_channels, out_channels, stride=1,\n",
    "                    cardinality=cardinality, shrink=shrink,\n",
    "                    reduc_ratio_CBAM=reduc_ratio_CBAM,\n",
    "                    use_cbam=use_cbam,\n",
    "                    CBAM=self.CBAM))\n",
    "        return layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder_fc(x)\n",
    "        x = x.view(-1, self.in_channels_forward, self.in_height, self.in_width)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        out = self.layer4(x)\n",
    "        out1 = self.iso_conv(out)\n",
    "        out1=self.final_fc(out1.view(-1,360))\n",
    "        return out1.view(-1,36,10)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='linear')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class EnhancedMultiScaleAttentionGate(nn.Module):\n",
    "    def __init__(self, input_channels, gating_channels):\n",
    "        super(EnhancedMultiScaleAttentionGate, self).__init__()\n",
    "        self.W_g = nn.Conv2d(gating_channels, input_channels, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(input_channels, input_channels, kernel_size=1)\n",
    "        self.psi = nn.Conv2d(input_channels, 1, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, g):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.sigmoid(self.psi(g1 + x1))\n",
    "        return x * psi\n",
    "\n",
    "\n",
    "class Stage2Model(nn.Module):\n",
    "    def __init__(self, input_dim, out_size, features=32):\n",
    "        super(Stage2Model, self).__init__()\n",
    "        self.out_height, self.out_width = out_size\n",
    "        \n",
    "        # Embedding input dimension to spatial output\n",
    "        self.input_embed = nn.Sequential(\n",
    "            nn.Linear(input_dim, self.out_height * self.out_width),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # UNet encoder-decoder architecture\n",
    "        self.encoder1 = self._conv_block(2, features)\n",
    "        self.pool1 = nn.Conv2d(features, features, kernel_size=4, stride=2, padding=(3, 2))\n",
    "\n",
    "        self.encoder2 = self._conv_block(features, features * 2)\n",
    "        self.pool2 = nn.Conv2d(features * 2, features * 2, kernel_size=4, stride=2, padding=(3, 2))\n",
    "\n",
    "        self.encoder3 = self._conv_block(features * 2, features * 4)\n",
    "        self.pool3 = nn.Conv2d(features * 4, features * 4, kernel_size=4, stride=2, padding=(3, 2))\n",
    "\n",
    "        self.bottleneck = self._conv_block(features * 4, features * 8)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(features * 8, features * 4, kernel_size=4, stride=2, padding=(3, 2))\n",
    "        self.decoder3 = self._conv_block(features * 8, features * 4)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(features * 4, features * 2, kernel_size=4, stride=2, padding=(3, 2))\n",
    "        self.decoder2 = self._conv_block(features * 4, features * 2)\n",
    "\n",
    "        self.upconv1 = nn.ConvTranspose2d(features * 2, features, kernel_size=4, stride=2, padding=(3, 2))\n",
    "        self.decoder1 = self._conv_block(features * 2, 1)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(1, 1, kernel_size=1)\n",
    "        self.final_fc = nn.Linear(self.out_height * self.out_width, self.out_height * self.out_width)\n",
    "        \n",
    "        # Attention Gates for skip connections\n",
    "        self.attn_gate3 = EnhancedMultiScaleAttentionGate(features * 4, features * 4)\n",
    "        self.attn_gate2 = EnhancedMultiScaleAttentionGate(features * 2, features * 2)\n",
    "        self.attn_gate1 = EnhancedMultiScaleAttentionGate(features, features)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x, output1):\n",
    "        # Embed the input and concatenate with Stage1 output\n",
    "        input_embed = self.input_embed(x)\n",
    "        input_embed = input_embed.view(-1, 1, self.out_height, self.out_width)\n",
    "        stage2_input = torch.cat([input_embed, output1.unsqueeze(1)], dim=1)\n",
    "\n",
    "        # UNet forward pass\n",
    "        enc1 = self.encoder1(stage2_input)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool3(enc3))\n",
    "\n",
    "        # Decoder with attention gates\n",
    "        dec3 = self.upconv3(bottleneck)\n",
    "        attn3 = self.attn_gate3(enc3, dec3)  # Apply attention gate to skip connection\n",
    "        dec3 = torch.cat([dec3, attn3], dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        attn2 = self.attn_gate2(enc2, dec2)  # Apply attention gate to skip connection\n",
    "        dec2 = torch.cat([dec2, attn2], dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        attn1 = self.attn_gate1(enc1, dec1)  # Apply attention gate to skip connection\n",
    "        dec1 = torch.cat([dec1, attn1], dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        \n",
    "        output2 = self.final_conv(dec1)\n",
    "        output2 = self.final_fc(output2.view(-1, self.out_height * self.out_width))\n",
    "        \n",
    "        return output2.view(-1, self.out_height, self.out_width)\n",
    "\n",
    "    def _conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='leaky_relu', a=0.2) \n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='linear')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training function for Stage 2 with loss history, test loss, and batch size scheduler\n",
    "def train_stage2(stage1_model, stage2_model, train_dataset, test_loader, optimizer, scheduler, criterion, num_epochs, scaler, batch_epoch, batches):\n",
    "    stage1_model.eval()  # Stage1Model is frozen and in evaluation mode\n",
    "    stage2_model.train()  # Stage2Model will be trained\n",
    "    \n",
    "    train_loss_history = []  # List to store training loss per epoch\n",
    "    test_loss_history = []   # List to store test loss per epoch\n",
    "    \n",
    "    # Initialize batch size scheduler\n",
    "    current_batch_idx = 0\n",
    "    batch_size = batches[current_batch_idx]\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # TQDM progress bar for epochs\n",
    "    with tqdm(range(1, num_epochs + 1), desc=\"Training Stage 2\", unit=\"epoch\") as progress_bar:\n",
    "        for epoch in progress_bar:\n",
    "            running_train_loss = 0.0  # Track running train loss\n",
    "            \n",
    "            # Update batch size based on the current epoch\n",
    "            if  epoch == batch_epoch[current_batch_idx]:\n",
    "                current_batch_idx += 1\n",
    "                batch_size = batches[current_batch_idx]\n",
    "                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "            # Loop over batches in training set\n",
    "            for inputs, iso_targets, res_targets in train_loader:\n",
    "                optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "                # Forward pass through Stage 1 (with no gradient tracking)\n",
    "                with torch.no_grad():\n",
    "                    out1 = stage1_model(inputs)\n",
    "                \n",
    "                # Forward pass through Stage 2 (with mixed precision)\n",
    "                with autocast('cuda'):\n",
    "                    outputs = stage2_model(inputs, out1)  # Pass Stage1 output to Stage2\n",
    "                    loss = criterion(outputs, res_targets)  # Compute loss\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                running_train_loss += loss.item() * inputs.size(0)  # Update running loss\n",
    "            \n",
    "            # Calculate average training loss for the epoch\n",
    "            epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "            train_loss_history.append(epoch_train_loss)\n",
    "            \n",
    "            # Evaluate test loss after each epoch\n",
    "            stage2_model.eval()  # Switch to evaluation mode for test set\n",
    "            running_test_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for inputs, iso_targets, res_targets in test_loader:\n",
    "                    with autocast('cuda'):\n",
    "                        out1 = stage1_model(inputs)\n",
    "                        outputs = stage2_model(inputs, out1)\n",
    "                        loss = criterion(outputs, res_targets)\n",
    "                    running_test_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            epoch_test_loss = running_test_loss / len(test_loader.dataset)\n",
    "            test_loss_history.append(epoch_test_loss)\n",
    "            \n",
    "            # Switch back to training mode\n",
    "            stage2_model.train()\n",
    "            \n",
    "            # Update the learning rate scheduler based on the loss\n",
    "            scheduler.step(epoch_train_loss)\n",
    "            \n",
    "            # Update the progress bar with current epoch and training loss\n",
    "            progress_bar.set_postfix({\n",
    "                'Epoch': epoch,\n",
    "                'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "                'Test Loss': f\"{epoch_test_loss:.4f}\",\n",
    "                'batch size': f\"{batch_size:.0f}\",\n",
    "                'Lr ': f\"{optimizer.param_groups[0]['lr']:.8f}\"\n",
    "            })\n",
    "    \n",
    "    return train_loss_history, test_loss_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Set the seed\n",
    "set_seed(7)\n",
    "\n",
    "# Instantiate Stage1Model\n",
    "conv_block = Resnext_bottleneck_block\n",
    "convt_block = Resnext_bottleneck_transpose_block\n",
    "cbam_module = CBAM\n",
    "\n",
    "stage1_params = {\n",
    "    'decoder_in': (512, 4, 2),\n",
    "    'out_size': (36, 10),\n",
    "    'conv_block': conv_block,\n",
    "    'convt_block': convt_block,\n",
    "    'n_blocks': (2, 3, 2, 4),\n",
    "    'decoder_channel_shrink': 1,\n",
    "    'width_ratio': 1,\n",
    "    'use_cbam': (True, False, True, False),\n",
    "    'CBAM': cbam_module,\n",
    "    'CBAM_skip': True,\n",
    "}\n",
    "\n",
    "stage1_model = Stage1Model(**stage1_params).to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate Stage2Model with UNet inside\n",
    "stage2_model = Stage2Model(input_dim=7, out_size=(36, 10), ).to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Stage 2: 100%|██████████| 600/600 [18:39<00:00,  1.87s/epoch, Epoch=600, Train Loss=0.0016, Test Loss=0.0037, batch size=256, Lr =0.00006250]\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer, scheduler, and loss function for Stage 2\n",
    "learning_rate_stage2 = 1e-3\n",
    "num_epochs_stage2 = 600\n",
    "weight_decay_stage2 = 1e-5\n",
    "\n",
    "# torch.use_deterministic_algorithms(False) \n",
    "    \n",
    "optimizer_stage2 = optim.Adam(stage2_model.parameters(), lr=learning_rate_stage2, weight_decay=weight_decay_stage2)\n",
    "scheduler_stage2 = ReduceLROnPlateau(optimizer_stage2, mode='min', factor=0.5, patience=15)\n",
    "criterion_stage2 = nn.L1Loss()\n",
    "\n",
    "# Data loaders for Stage 2\n",
    "# batch_size_stage2 = 16\n",
    "# train_loader_stage2 = DataLoader(train_dataset, batch_size=batch_size_stage2, shuffle=True)\n",
    "test_loader_stage2 = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "# Mixed precision setup for Stage 2 (fix for future warning)\n",
    "scaler_stage2 = torch.amp.GradScaler()\n",
    "\n",
    "batch_epoch = [200, 400, 1000]  \n",
    "batches = [32, 64, 256]                      \n",
    "\n",
    "# Example usage for Stage 2\n",
    "train_loss_history_stage2, test_loss_history_stage2 = train_stage2(\n",
    "    stage1_model, stage2_model, train_dataset, test_loader_stage2, \n",
    "    optimizer_stage2, scheduler_stage2, criterion_stage2, \n",
    "    num_epochs_stage2, scaler_stage2, batch_epoch, batches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Output 1 - MSE: 0.0001483383384766057, MAE: 0.0053728362545371056, R2: 0.9992623329162598, MAPE: 0.8887980133295059, R: 0.9996311442561985\n",
      "Train Output 2 - MSE: 1.594929381099064e-05, MAE: 0.001505478867329657, R2: 0.980930745601654, MAPE: 129.27244901657104, R: 0.9904264102134283\n",
      "Test Output 1 - MSE: 0.000298578612273559, MAE: 0.008552854880690575, R2: 0.9985069632530212, MAPE: 1.3339451514184475, R: 0.9992534057816923\n",
      "Test Output 2 - MSE: 0.00015137006994336843, MAE: 0.003702885238453746, R2: 0.8158720135688782, MAPE: 224.90262985229492, R: 0.9035423793659445\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "# Function to set the random seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "# Function to retrieve model outputs for both training and testing data\n",
    "def get_model_outputs(model_stage1, model_stage2, device, X_train_t, X_test_t):\n",
    "    model_stage1.to(device)\n",
    "    model_stage2.to(device)\n",
    "    model_stage1.eval()\n",
    "    model_stage2.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        X_train_t = X_train_t.to(device)\n",
    "        X_test_t = X_test_t.to(device)\n",
    "\n",
    "        # Stage 1 forward pass\n",
    "        train_output1 = model_stage1(X_train_t)\n",
    "        test_output1 = model_stage1(X_test_t)\n",
    "\n",
    "        # Stage 2 forward pass\n",
    "        train_output2 = model_stage2(X_train_t, train_output1)\n",
    "        test_output2 = model_stage2(X_test_t, test_output1)\n",
    "\n",
    "    return (train_output1, train_output2), (test_output1, test_output2)\n",
    "\n",
    "\n",
    "# Function to calculate metrics for true vs. predicted values\n",
    "# Function to calculate metrics for true vs. predicted values\n",
    "def calculate_metrics(true, pred):\n",
    "    # Move tensors to CPU and convert to NumPy arrays if they are not already\n",
    "    if isinstance(true, torch.Tensor):\n",
    "        true = true.cpu().numpy()\n",
    "    if isinstance(pred, torch.Tensor):\n",
    "        pred = pred.cpu().numpy()\n",
    "\n",
    "    # Flatten the arrays\n",
    "    true_flat = true.reshape(-1)\n",
    "    pred_flat = pred.reshape(-1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(true_flat, pred_flat)\n",
    "    mae = mean_absolute_error(true_flat, pred_flat)\n",
    "    r2 = r2_score(true_flat, pred_flat)\n",
    "    mape = np.mean(np.abs((true_flat - pred_flat) / true_flat)) * 100\n",
    "    r, _= pearsonr(true_flat, pred_flat)\n",
    "    return mse, mae, r2, mape, r\n",
    "\n",
    "# Retrieve model outputs on CUDA (if available) or CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "(train_output1, train_output2), (test_output1, test_output2) = get_model_outputs(stage1_model, stage2_model, device, X_train_t, X_test_t)\n",
    "\n",
    "# Compute predictions for training and testing data\n",
    "train_pred1 = train_output1\n",
    "train_pred2 = (train_output2)\n",
    "test_pred1 = (test_output1)\n",
    "test_pred2 = (test_output2)\n",
    "\n",
    "# Use the wrapper function for true values; no need to move to device since they're already NumPy arrays\n",
    "train_org1 =iso_train_t\n",
    "train_org2 = res_train_t\n",
    "test_org1 = iso_test_t\n",
    "test_org2 = res_test_t\n",
    "\n",
    "# Calculate metrics for both outputs\n",
    "train_metrics1 = calculate_metrics(train_org1, train_pred1)\n",
    "test_metrics1 = calculate_metrics(test_org1, test_pred1)\n",
    "train_metrics2 = calculate_metrics(train_org2, train_pred2)\n",
    "test_metrics2 = calculate_metrics(test_org2, test_pred2)\n",
    "\n",
    "# Print results for training data (Output 1)\n",
    "print(f\"Train Output 1 - MSE: {train_metrics1[0]}, MAE: {train_metrics1[1]}, R2: {train_metrics1[2]}, MAPE: {train_metrics1[3]}, R: {train_metrics1[4]}\")\n",
    "# Print results for training data (Output 2)\n",
    "print(f\"Train Output 2 - MSE: {train_metrics2[0]}, MAE: {train_metrics2[1]}, R2: {train_metrics2[2]}, MAPE: {train_metrics2[3]}, R: {train_metrics2[4]}\")\n",
    "\n",
    "# Print results for testing data (Output 1)\n",
    "print(f\"Test Output 1 - MSE: {test_metrics1[0]}, MAE: {test_metrics1[1]}, R2: {test_metrics1[2]}, MAPE: {test_metrics1[3]}, R: {test_metrics1[4]}\")\n",
    "# Print results for testing data (Output 2)\n",
    "print(f\"Test Output 2 - MSE: {test_metrics2[0]}, MAE: {test_metrics2[1]}, R2: {test_metrics2[2]}, MAPE: {test_metrics2[3]}, R: {test_metrics2[4]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
